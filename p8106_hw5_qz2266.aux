\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {subsection}{Question 1}{1}{section*.1}\protected@file@percent }
\newlabel{question-1}{{}{1}{Question 1}{section*.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{(a) Fit a support vector classifier (linear kernel) to the training data.}{1}{section*.2}\protected@file@percent }
\newlabel{a-fit-a-support-vector-classifier-linear-kernel-to-the-training-data.}{{}{1}{(a) Fit a support vector classifier (linear kernel) to the training data}{section*.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{b) Fit a support vector machine with a radial kernel to the training data.}{4}{section*.3}\protected@file@percent }
\newlabel{b-fit-a-support-vector-machine-with-a-radial-kernel-to-the-training-data.}{{}{4}{b) Fit a support vector machine with a radial kernel to the training data}{section*.3}{}}
\@writefile{toc}{\contentsline {subsection}{Question 2}{7}{section*.4}\protected@file@percent }
\newlabel{question-2}{{}{7}{Question 2}{section*.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{a) Using hierarchical clustering with complete linkage and Euclidean distance, cluster the states. Cut the dendrogram at a height that results in three distinct clusters.}{7}{section*.5}\protected@file@percent }
\newlabel{a-using-hierarchical-clustering-with-complete-linkage-and-euclidean-distance-cluster-the-states.-cut-the-dendrogram-at-a-height-that-results-in-three-distinct-clusters.}{{}{7}{a) Using hierarchical clustering with complete linkage and Euclidean distance, cluster the states. Cut the dendrogram at a height that results in three distinct clusters}{section*.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{b) Hierarchically cluster the states using complete linkage and Euclidean distance, after scaling the variables to have standard deviation one.}{9}{section*.6}\protected@file@percent }
\newlabel{b-hierarchically-cluster-the-states-using-complete-linkage-and-euclidean-distance-after-scaling-the-variables-to-have-standard-deviation-one.}{{}{9}{b) Hierarchically cluster the states using complete linkage and Euclidean distance, after scaling the variables to have standard deviation one}{section*.6}{}}
\gdef \LT@i {\LT@entry 
    {2}{186.00002pt}\LT@entry 
    {2}{51.16684pt}}
\@writefile{toc}{\contentsline {subsubsection}{c). Does scaling the variables change the clustering results? Why? In your opinion, should the variables be scaled before the inter-observation dissimilarities are computed?}{10}{section*.7}\protected@file@percent }
\newlabel{c.-does-scaling-the-variables-change-the-clustering-results-why-in-your-opinion-should-the-variables-be-scaled-before-the-inter-observation-dissimilarities-are-computed}{{}{10}{c). Does scaling the variables change the clustering results? Why? In your opinion, should the variables be scaled before the inter-observation dissimilarities are computed?}{section*.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{Data summary}}{10}{table.1}\protected@file@percent }
\gdef \LT@ii {\LT@entry 
    {1}{67.02849pt}\LT@entry 
    {1}{55.59099pt}\LT@entry 
    {1}{73.02849pt}\LT@entry 
    {1}{42.49768pt}\LT@entry 
    {1}{38.15349pt}\LT@entry 
    {1}{33.77617pt}\LT@entry 
    {1}{42.49768pt}\LT@entry 
    {1}{42.49768pt}\LT@entry 
    {1}{42.49768pt}\LT@entry 
    {1}{32.15349pt}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{Data summary}}{11}{table.1}\protected@file@percent }
\gdef \@abspage@last{11}
